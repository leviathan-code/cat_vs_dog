{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vllla\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:\\\\Users\\\\vllla\\Downloads\\\\kagglecatsanddogs_5340_resize\\\\PetImages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 32\n",
    "img_width = 32\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24994 files belonging to 2 classes.\n",
      "Using 19996 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  seed=123,\n",
    "  subset=\"training\",\n",
    "  validation_split = 0.2,\n",
    "  shuffle = True,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24994 files belonging to 2 classes.\n",
      "Using 4998 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset=\"validation\",\n",
    "  image_size=(img_height, img_width), \n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)# чтобы быстрее работал\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dog', 'Cat']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12499/12499 [00:05<00:00, 2368.74it/s]\n",
      "100%|██████████| 12495/12495 [00:05<00:00, 2411.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(data_dir,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (img_height, img_width))  # resize to normalize data size\n",
    "                train_ds.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e: \n",
    "                pass\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in train_ds:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, img_width, img_height, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn():\n",
    "    model = tf.keras.Sequential([\n",
    "        # tf.keras.layers.Resizing(img_height, img_width,),\n",
    "        # tf.keras.layers.layers.layers.Rescaling(1./255),\n",
    "        tf.keras.layers.Conv2D(16, kernel_size = (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, kernel_size = (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "        tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 16, 16, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 179,874\n",
      "Trainable params: 179,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nn()\n",
    "# model.build(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0003\n",
    "optimizer = keras.optimizers.Adam(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.ModelCheckpoint('cifar_weight.h5', save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer = optimizer,\n",
    "  metrics = [keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir = 'logs/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vllla\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 20s 31ms/step - loss: 0.7444 - sparse_categorical_accuracy: 0.5029 - val_loss: 0.6946 - val_sparse_categorical_accuracy: 0.5114\n",
      "Epoch 2/9\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.7268 - sparse_categorical_accuracy: 0.5004 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.5114\n",
      "Epoch 3/9\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.7136 - sparse_categorical_accuracy: 0.5010 - val_loss: 0.6955 - val_sparse_categorical_accuracy: 0.4886\n",
      "Epoch 4/9\n",
      "625/625 [==============================] - 8s 12ms/step - loss: 0.7068 - sparse_categorical_accuracy: 0.4996 - val_loss: 0.6958 - val_sparse_categorical_accuracy: 0.5114\n",
      "Epoch 5/9\n",
      "625/625 [==============================] - 9s 15ms/step - loss: 0.7028 - sparse_categorical_accuracy: 0.5000 - val_loss: 0.7092 - val_sparse_categorical_accuracy: 0.4886\n",
      "Epoch 6/9\n",
      "625/625 [==============================] - 9s 14ms/step - loss: 0.6996 - sparse_categorical_accuracy: 0.5002 - val_loss: 0.6937 - val_sparse_categorical_accuracy: 0.5116\n",
      "Epoch 7/9\n",
      "625/625 [==============================] - 9s 15ms/step - loss: 0.6967 - sparse_categorical_accuracy: 0.5019 - val_loss: 0.6943 - val_sparse_categorical_accuracy: 0.4886\n",
      "Epoch 8/9\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.6959 - sparse_categorical_accuracy: 0.5009 - val_loss: 0.6930 - val_sparse_categorical_accuracy: 0.5112\n",
      "Epoch 9/9\n",
      "625/625 [==============================] - 13s 20ms/step - loss: 0.6951 - sparse_categorical_accuracy: 0.5036 - val_loss: 0.6944 - val_sparse_categorical_accuracy: 0.4886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2401121e200>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  x = train_ds,\n",
    "   batch_size=32,\n",
    "  epochs=9,\n",
    "  validation_data = val_ds,\n",
    "  callbacks = [tensorboard],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_cat_vs_dog.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_cat_vs_dog.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('CNN_cat_vs_dog.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('cifar_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"CNN_cat_vs_dog.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00453295, 0.99546707], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"C:\\Users\\vllla\\Downloads\\kagglecatsanddogs_5340\\PetImages\\test\\Cat\\1005.jpg\"\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    r\"C:\\Users\\vllla\\Downloads\\shutterstock_211592482-e1528481509952.jpg\",\n",
    "    target_size=(img_height, img_width)\n",
    ")\n",
    "# image = tf.keras.preprocessing.image.load_img(r\"C:\\Users\\vllla\\Downloads\\kagglecatsanddogs_5340\\PetImages\\Dog\\1425.jpg\")\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "predictions = model.predict(input_arr)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5162315 , 0.48376855], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path =  r\"C:\\Users\\vllla\\Downloads\\kagglecatsanddogs_5340\\PetImages\\Cat\\43.jpg\"\n",
    "\n",
    "\n",
    "img_array = cv2.imread(os.path.join(path), cv2.IMREAD_UNCHANGED)  # convert to array\n",
    "new_array = cv2.resize(img_array, (img_height, img_width))  # resize to normalize data size\n",
    "new_array = np.array(new_array).reshape(-1, img_width, img_height, 3)\n",
    "predictions = model.predict(new_array)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9965599 , 0.00344004], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99546707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dog'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=np.where(predictions[0] == max(predictions[0]))[0][0]\n",
    "print(predictions[0][i])\n",
    "class_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to Cat with a 68.16%.\n"
     ]
    }
   ],
   "source": [
    "print(f\"This image most likely belongs to {labels[i]} with a {round(100 * predictions[0][i], 2)}%.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vllla\\AppData\\Local\\Temp\\ipykernel_668\\1616381710.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predictions = model.predict_generator(img_array)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(img_array)\n",
    "score = np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PrefetchDataset' object has no attribute 'class_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vllla\\Downloads\\ML\\work_nn.ipynb Ячейка 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vllla/Downloads/ML/work_nn.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m labels \u001b[39m=\u001b[39m (train_ds\u001b[39m.\u001b[39;49mclass_indices)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PrefetchDataset' object has no attribute 'class_indices'"
     ]
    }
   ],
   "source": [
    "labels = (train_ds)\n",
    "# labels = dict((v,k) for k,v in labels.items())\n",
    "# predictions = [labels[k] for k in score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat', 'Dog']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames=val_ds.filenames\n",
    "# results=pd.DataFrame({\"Filename\":filenames,\n",
    "#                       \"Predictions\":predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'class_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vllla\\Downloads\\ML\\work_nn.ipynb Ячейка 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vllla/Downloads/ML/work_nn.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m class_names \u001b[39m=\u001b[39m train_ds\u001b[39m.\u001b[39;49mclass_indices\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'class_indices'"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weight.txt', 'w') as f:\n",
    "    for i in class_names:\n",
    "        f.write(f'{i} {class_names[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47664538\n"
     ]
    }
   ],
   "source": [
    "print(score[0][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog 0.52335465\n"
     ]
    }
   ],
   "source": [
    "if score[0][0].numpy() > 0.5:\n",
    "    print('cat', score[0][0].numpy())\n",
    "else:\n",
    "    print( 'dog', score[0][1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to  with a 47.66%.\n"
     ]
    }
   ],
   "source": [
    "print(f\"This image most likely belongs to  with a {round(100 * score[0][0].numpy(), 2)}%.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image \n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "path = Path(data_dir).rglob(\"*\\*.jpg\")\n",
    "for img_p in path:\n",
    "    try:\n",
    "        img = PIL.Image.open(img_p)\n",
    "    except PIL.UnidentifiedImageError:\n",
    "            print(img_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vllla\\AppData\\Local\\Temp\\ipykernel_10156\\699106473.py:5: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img.resize((32, 32), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "path = Path(data_dir).rglob(\"*\\*.jpg\")\n",
    "for img_p in path:\n",
    "    try:\n",
    "        img = Image.open(img_p).convert('RGB')\n",
    "        img.resize((32, 32), Image.ANTIALIAS)\n",
    "        # print(img_p)\n",
    "    except PIL.UnidentifiedImageError:\n",
    "            print(img_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d67d3c09c8e335c1862db20e5720599345c6f30eb744b224d113fae0e8d50509"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
